# AI Fine-tuning Sistemi - MEB MÃ¼fredatÄ±

Bu sistem, OpenAI modellerini MEB mÃ¼fredatÄ±na uygun ÅŸekilde fine-tune etmek iÃ§in geliÅŸtirilmiÅŸtir.

## ğŸ¯ AmaÃ§

Genel amaÃ§lÄ± dil modellerini TÃ¼rkiye'deki Ã¶ÄŸrencilere MEB mÃ¼fredatÄ±na uygun eÄŸitim verebilecek ÅŸekilde Ã¶zelleÅŸtirmek.

## ğŸ¤– Desteklenen AI SaÄŸlayÄ±cÄ±larÄ±

### OpenAI
- GPT-3.5-turbo (fine-tuning desteÄŸi)
- GPT-4 (temel model)
- Custom fine-tuned modeller

### DeepSeek
- **DeepSeek-V3**: Genel amaÃ§lÄ±, hÄ±zlÄ± ve ekonomik
- **DeepSeek-R1**: GeliÅŸmiÅŸ muhakeme yeteneÄŸi, Ã¶zellikle matematik ve problem Ã§Ã¶zme iÃ§in ideal
- OpenAI API uyumlu (kolay entegrasyon)
- Fine-tuning gerektirmez, doÄŸrudan kullanÄ±ma hazÄ±r

## ğŸ“ KlasÃ¶r YapÄ±sÄ±

```
ai-fine-tuning/
â”œâ”€â”€ data/                    # Veri dosyalarÄ±
â”‚   â”œâ”€â”€ raw/                # Ham eÄŸitim verileri (JSONL)
â”‚   â”œâ”€â”€ processed/          # Ä°ÅŸlenmiÅŸ veriler
â”‚   â””â”€â”€ validation/         # DoÄŸrulama verileri
â”œâ”€â”€ models/                 # Model bilgileri ve Ã§Ä±ktÄ±larÄ±
â”œâ”€â”€ scripts/                # Python scriptleri
â”‚   â”œâ”€â”€ prepare_data.py     # Veri hazÄ±rlama
â”‚   â”œâ”€â”€ validate_data.py    # Veri doÄŸrulama
â”‚   â”œâ”€â”€ openai_client.py    # OpenAI API istemcisi
â”‚   â”œâ”€â”€ train_model.py      # EÄŸitim yÃ¶netimi
â”‚   â””â”€â”€ model_evaluator.py  # Model deÄŸerlendirme
â”œâ”€â”€ config/                 # KonfigÃ¼rasyon dosyalarÄ±
â”œâ”€â”€ logs/                   # Log dosyalarÄ±
â””â”€â”€ results/                # Test sonuÃ§larÄ±
```

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### 1. Kurulum

```bash
# Gerekli paketleri yÃ¼kle
pip install -r requirements.txt

# Environment deÄŸiÅŸkenlerini ayarla
export OPENAI_API_KEY="your-api-key"

# DeepSeek kullanmak iÃ§in (opsiyonel)
export DEEPSEEK_API_KEY="your-deepseek-api-key"
```

### 2. Veri HazÄ±rlama

```bash
cd scripts

# Ham verileri iÅŸle
python prepare_data.py

# Veriyi doÄŸrula
python validate_data.py
```

### 3. Fine-tuning BaÅŸlatma

```bash
# Tam pipeline'Ä± Ã§alÄ±ÅŸtÄ±r
python train_model.py

# Veya sadece Ã¶rnek veri ile test
python train_model.py --sample 100
```

### 4. Model Test Etme

```bash
# HÄ±zlÄ± test
python model_evaluator.py ft:gpt-3.5-turbo:org:meb-ogretmen:xyz --quick

# KapsamlÄ± test
python model_evaluator.py ft:gpt-3.5-turbo:org:meb-ogretmen:xyz
```

## ğŸ“Š Veri FormatÄ±

### JSONL FormatÄ±

Her satÄ±r bir konuÅŸmayÄ± temsil eder:

```json
{
  "messages": [
    {
      "role": "system",
      "content": "Sen 5. sÄ±nÄ±f Ã¶ÄŸrencilerine matematik Ã¶ÄŸreten..."
    },
    {
      "role": "user",
      "content": "Kesirler nedir?"
    },
    {
      "role": "assistant",
      "content": "Kesirler, bir bÃ¼tÃ¼nÃ¼n parÃ§alarÄ±nÄ± gÃ¶steren..."
    }
  ]
}
```

### Veri Gereksinimleri

- Minimum 10 Ã¶rnek (Ã¶nerilen: 50-100)
- Her Ã¶rnek max 4096 token
- Dengeli sÄ±nÄ±f ve konu daÄŸÄ±lÄ±mÄ±
- DoÄŸru TÃ¼rkÃ§e yazÄ±m ve gramer

## ğŸ› ï¸ Scriptler

### prepare_data.py

Veri hazÄ±rlama ve iÅŸleme:

```bash
python prepare_data.py --raw-path ../data/raw --processed-path ../data/processed
```

**Ã–zellikler:**
- JSONL format doÄŸrulama
- Veri augmentasyonu
- Train/validation split (90/10)
- Token sayÄ±mÄ±

### validate_data.py

Veri kalite kontrolÃ¼:

```bash
python validate_data.py --data-path ../data/processed
```

**Kontroller:**
- Format doÄŸruluÄŸu
- Token limitleri
- Rol sÄ±ralamasÄ±
- Ä°statistiksel analiz

### openai_client.py

OpenAI API yÃ¶netimi:

```bash
# Dosya yÃ¼kle
python openai_client.py upload train.jsonl

# Fine-tuning baÅŸlat
python openai_client.py create file-abc123 --epochs 3

# Ä°ÅŸlemi izle
python openai_client.py monitor ftjob-xyz789

# Model test et
python openai_client.py test ft:model:name "Test sorusu"
```

### train_model.py

End-to-end eÄŸitim:

```bash
# VarsayÄ±lan ayarlarla
python train_model.py

# Ã–zel konfigÃ¼rasyon
python train_model.py --config custom_config.json

# Ã–rnek veri ile
python train_model.py --sample 50
```

### model_evaluator.py

Model performans deÄŸerlendirme:

```bash
# VarsayÄ±lan testler
python model_evaluator.py model-name

# Ã–zel test dosyasÄ±
python model_evaluator.py model-name --test-file tests.json
```

## ğŸ“ˆ Metrikler

### DeÄŸerlendirme Kriterleri

1. **DoÄŸruluk (Accuracy)**: Verilen bilginin doÄŸruluÄŸu
2. **Ä°lgililik (Relevance)**: Soruya uygun cevap
3. **TamlÄ±k (Completeness)**: Yeterli detay
4. **Pedagoji**: Ã–ÄŸretici yaklaÅŸÄ±m
5. **Dil Kalitesi**: AnlaÅŸÄ±lÄ±r TÃ¼rkÃ§e
6. **Seviye UygunluÄŸu**: SÄ±nÄ±f seviyesine uyum

### BaÅŸarÄ± Metrikleri

- Genel baÅŸarÄ± skoru: > 0.8
- YanÄ±t sÃ¼resi: < 2 saniye
- Token verimliliÄŸi: Optimal kullanÄ±m

## ğŸ’° Maliyet Tahmini

### OpenAI GPT-3.5-turbo Fine-tuning

- **EÄŸitim**: $0.0080 / 1K token
- **KullanÄ±m**: $0.0030 / 1K token (input) + $0.0060 / 1K token (output)

### DeepSeek Modelleri (Fine-tuning gerekmez)

- **DeepSeek-V3**: $0.0001 / 1K token (input) + $0.0003 / 1K token (output)
- **DeepSeek-R1**: $0.0005 / 1K token (input) + $0.0020 / 1K token (output)

**Not**: DeepSeek modelleri OpenAI'ye gÃ¶re %90'a varan maliyet tasarrufu saÄŸlar!

### Ã–rnek Maliyet KarÅŸÄ±laÅŸtÄ±rmasÄ±

100 konuÅŸma Ã— 500 token = 50,000 token
- OpenAI GPT-3.5: ~$0.40
- DeepSeek-V3: ~$0.02 (20x daha ucuz)

## ğŸ”§ Backend Entegrasyonu

### AI Servisi GÃ¼ncelleme

```python
# Fine-tuned modeli aktif et
ai_service.update_fine_tuned_model("ft:gpt-3.5-turbo:org:suffix:id")
```

### API Endpoints

- `GET /api/fine-tuning/models` - Model listesi
- `PUT /api/fine-tuning/models/fine-tuned` - Model gÃ¼ncelle
- `POST /api/fine-tuning/upload-training-data` - Veri yÃ¼kle
- `GET /api/fine-tuning/test-model/{model_name}` - Model test

## ğŸ“ En Ä°yi Uygulamalar

### Veri Kalitesi

1. **Ã‡eÅŸitlilik**: FarklÄ± konular ve soru tipleri
2. **TutarlÄ±lÄ±k**: AynÄ± Ã¶ÄŸretim stili
3. **DoÄŸruluk**: MEB mÃ¼fredatÄ±na uygunluk
4. **GÃ¼ncellik**: Son mÃ¼fredat deÄŸiÅŸiklikleri

### Model SeÃ§imi

- **DeepSeek-V3**: En dÃ¼ÅŸÃ¼k maliyet, hÄ±zlÄ± yanÄ±t
- **DeepSeek-R1**: GeliÅŸmiÅŸ muhakeme, matematik iÃ§in ideal
- **GPT-3.5-turbo**: HÄ±z ve maliyet dengesi
- **GPT-4**: Maksimum kalite (en pahalÄ±)

### Ä°teratif GeliÅŸtirme

1. KÃ¼Ã§Ã¼k veri seti ile baÅŸla
2. Test et ve deÄŸerlendir
3. Veriyi geniÅŸlet
4. Tekrar eÄŸit

## ğŸš¨ Sorun Giderme

### SÄ±k KarÅŸÄ±laÅŸÄ±lan Hatalar

1. **Token limiti aÅŸÄ±mÄ±**: KonuÅŸmalarÄ± bÃ¶l
2. **Format hatasÄ±**: validate_data.py kullan
3. **API limitleri**: Rate limiting uygula
4. **Model bulunamadÄ±**: Model ID'yi kontrol et

### Debug ModlarÄ±

```bash
# DetaylÄ± loglar
export LOG_LEVEL=DEBUG

# Dry run (gerÃ§ek API Ã§aÄŸrÄ±sÄ± yapmaz)
python train_model.py --dry-run
```

## ğŸ“š Kaynaklar

- [OpenAI Fine-tuning Docs](https://platform.openai.com/docs/guides/fine-tuning)
- [MEB MÃ¼fredat](http://mufredat.meb.gov.tr)
- [Proje Wiki](wiki/Home.md)

## ğŸ¤ KatkÄ±da Bulunma

1. Yeni eÄŸitim verileri ekleyin
2. Test senaryolarÄ± geliÅŸtirin
3. Performans iyileÅŸtirmeleri Ã¶nerin
4. DokÃ¼mantasyonu gÃ¼ncelleyin

## ğŸ“„ Lisans

Bu proje [MIT LisansÄ±](LICENSE) altÄ±nda lisanslanmÄ±ÅŸtÄ±r. 