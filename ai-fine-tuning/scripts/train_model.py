#!/usr/bin/env python3
"""
Fine-tuning EÄŸitim YÃ¶netim Scripti
End-to-end fine-tuning sÃ¼recini yÃ¶netir.
"""

import os
import sys
import json
import argparse
from pathlib import Path
from datetime import datetime
from typing import Dict, Optional

# DiÄŸer scriptleri import et
sys.path.append(str(Path(__file__).parent))
from prepare_data import DataProcessor
from validate_data import DataValidator
from openai_client import FineTuningManager


class TrainingPipeline:
    """Fine-tuning eÄŸitim pipeline'Ä±"""
    
    def __init__(self, config_path: Optional[Path] = None):
        # KonfigÃ¼rasyon
        if config_path and config_path.exists():
            with open(config_path, 'r') as f:
                self.config = json.load(f)
        else:
            self.config = self._get_default_config()
        
        # Dizinler
        self.base_dir = Path(__file__).parent.parent
        self.raw_data_dir = self.base_dir / 'data' / 'raw'
        self.processed_data_dir = self.base_dir / 'data' / 'processed'
        self.models_dir = self.base_dir / 'models'
        self.results_dir = self.base_dir / 'results'
        
        # Dizinleri oluÅŸtur
        for dir_path in [self.processed_data_dir, self.models_dir, self.results_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)
    
    def _get_default_config(self) -> Dict:
        """VarsayÄ±lan konfigÃ¼rasyon"""
        return {
            "model": {
                "base_model": "gpt-3.5-turbo",
                "suffix": "meb-ogretmen",
                "temperature": 0.7,
                "max_tokens": 500
            },
            "training": {
                "n_epochs": 3,
                "batch_size": 1,
                "learning_rate_multiplier": 0.1,
                "validation_split": 0.1
            },
            "data": {
                "augmentation": True,
                "max_tokens_per_conversation": 4096,
                "sample_size": 0  # 0 = tÃ¼m veri
            }
        }
    
    def step1_prepare_data(self) -> Dict:
        """AdÄ±m 1: Veri hazÄ±rlama"""
        print("\n" + "="*60)
        print("ADIM 1: VERÄ° HAZIRLAMA")
        print("="*60)
        
        processor = DataProcessor(
            str(self.raw_data_dir),
            str(self.processed_data_dir)
        )
        
        stats = processor.process_all_data()
        
        # Sample oluÅŸtur
        if self.config['data']['sample_size'] > 0:
            processor.create_sample_dataset(self.config['data']['sample_size'])
        
        return stats
    
    def step2_validate_data(self) -> bool:
        """AdÄ±m 2: Veri doÄŸrulama"""
        print("\n" + "="*60)
        print("ADIM 2: VERÄ° DOÄRULAMA")
        print("="*60)
        
        validator = DataValidator(str(self.processed_data_dir))
        
        # Train verisini doÄŸrula
        train_file = self.processed_data_dir / 'train.jsonl'
        if not train_file.exists():
            print("âŒ train.jsonl bulunamadÄ±!")
            return False
        
        stats = validator.analyze_dataset(train_file)
        validator.print_report(stats)
        
        # Format hatasÄ± var mÄ±?
        if stats['format_errors']:
            print(f"\nâŒ {len(stats['format_errors'])} format hatasÄ± bulundu!")
            return False
        
        # Token limiti kontrolÃ¼
        over_limit = validator.check_token_limits(
            train_file, 
            self.config['data']['max_tokens_per_conversation']
        )
        
        if over_limit:
            print(f"\nâš ï¸  {len(over_limit)} konuÅŸma token limitini aÅŸÄ±yor!")
            response = input("Devam etmek istiyor musunuz? (e/h): ")
            if response.lower() != 'e':
                return False
        
        return True
    
    def step3_upload_data(self, manager: FineTuningManager) -> str:
        """AdÄ±m 3: Veriyi yÃ¼kle"""
        print("\n" + "="*60)
        print("ADIM 3: VERÄ°YÄ° YÃœKLE")
        print("="*60)
        
        # Hangi dosyayÄ± yÃ¼kleyeceÄŸiz?
        if self.config['data']['sample_size'] > 0:
            train_file = self.processed_data_dir / 'sample.jsonl'
        else:
            train_file = self.processed_data_dir / 'train.jsonl'
        
        if not train_file.exists():
            raise FileNotFoundError(f"{train_file} bulunamadÄ±!")
        
        # Maliyet tahmini
        cost_estimate = manager.estimate_cost(train_file)
        print(f"\nğŸ’° Tahmini maliyet: {cost_estimate['estimated_training_cost']}")
        print(f"   Token sayÄ±sÄ±: {cost_estimate['estimated_tokens']:,}")
        
        response = input("\nDevam etmek istiyor musunuz? (e/h): ")
        if response.lower() != 'e':
            print("Ä°ptal edildi.")
            sys.exit(0)
        
        # DosyayÄ± yÃ¼kle
        file_id = manager.upload_training_file(train_file)
        return file_id
    
    def step4_start_training(self, manager: FineTuningManager, file_id: str) -> str:
        """AdÄ±m 4: EÄŸitimi baÅŸlat"""
        print("\n" + "="*60)
        print("ADIM 4: EÄÄ°TÄ°MÄ° BAÅLAT")
        print("="*60)
        
        hyperparameters = {
            "n_epochs": self.config['training']['n_epochs'],
            "batch_size": self.config['training']['batch_size'],
            "learning_rate_multiplier": self.config['training']['learning_rate_multiplier']
        }
        
        job_id = manager.create_fine_tuning_job(
            file_id,
            model=self.config['model']['base_model'],
            suffix=self.config['model']['suffix'],
            hyperparameters=hyperparameters
        )
        
        return job_id
    
    def step5_monitor_training(self, manager: FineTuningManager, job_id: str) -> str:
        """AdÄ±m 5: EÄŸitimi izle"""
        print("\n" + "="*60)
        print("ADIM 5: EÄÄ°TÄ°MÄ° Ä°ZLE")
        print("="*60)
        
        model_name = manager.monitor_job(job_id, check_interval=30)
        return model_name
    
    def step6_test_model(self, manager: FineTuningManager, model_name: str):
        """AdÄ±m 6: Modeli test et"""
        print("\n" + "="*60)
        print("ADIM 6: MODELÄ° TEST ET")
        print("="*60)
        
        test_prompts = [
            "5. sÄ±nÄ±f Ã¶ÄŸrencisiyim. Kesirler konusunu anlamadÄ±m.",
            "8. sÄ±nÄ±f matematik Pisagor teoremi nedir?",
            "3. sÄ±nÄ±f Ã¶ÄŸrencisiyim. Ã‡arpma iÅŸlemini Ã¶ÄŸrenmek istiyorum.",
            "11. sÄ±nÄ±f tÃ¼rev konusunu aÃ§Ä±klar mÄ±sÄ±n?",
            "6. sÄ±nÄ±f fen bilimleri vÃ¼cudumuzda sistemler"
        ]
        
        results = []
        
        for i, prompt in enumerate(test_prompts, 1):
            print(f"\nğŸ§ª Test {i}/{len(test_prompts)}")
            print(f"Soru: {prompt}")
            
            try:
                response = manager.test_fine_tuned_model(model_name, prompt)
                print(f"Cevap: {response[:200]}...")
                
                results.append({
                    "prompt": prompt,
                    "response": response,
                    "success": True
                })
            except Exception as e:
                print(f"Hata: {e}")
                results.append({
                    "prompt": prompt,
                    "error": str(e),
                    "success": False
                })
        
        # SonuÃ§larÄ± kaydet
        self._save_test_results(model_name, results)
        
        # BaÅŸarÄ± oranÄ±
        success_count = sum(1 for r in results if r['success'])
        print(f"\nâœ… BaÅŸarÄ± oranÄ±: {success_count}/{len(results)}")
    
    def _save_test_results(self, model_name: str, results: list):
        """Test sonuÃ§larÄ±nÄ± kaydet"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        results_file = self.results_dir / f"test_results_{timestamp}.json"
        
        data = {
            "model": model_name,
            "timestamp": timestamp,
            "config": self.config,
            "results": results
        }
        
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ“ Test sonuÃ§larÄ± kaydedildi: {results_file}")
    
    def run_full_pipeline(self):
        """Tam pipeline'Ä± Ã§alÄ±ÅŸtÄ±r"""
        print("\nğŸš€ FINE-TUNING PIPELINE BAÅLATILIYOR")
        print("="*60)
        
        try:
            # AdÄ±m 1: Veri hazÄ±rlama
            data_stats = self.step1_prepare_data()
            print(f"\nâœ… Veri hazÄ±rlandÄ±: {data_stats['total']} konuÅŸma")
            
            # AdÄ±m 2: Veri doÄŸrulama
            if not self.step2_validate_data():
                print("\nâŒ Veri doÄŸrulama baÅŸarÄ±sÄ±z!")
                return
            
            # OpenAI client oluÅŸtur
            manager = FineTuningManager()
            
            # AdÄ±m 3: Veriyi yÃ¼kle
            file_id = self.step3_upload_data(manager)
            
            # AdÄ±m 4: EÄŸitimi baÅŸlat
            job_id = self.step4_start_training(manager, file_id)
            
            # Model bilgilerini kaydet
            model_info = {
                "file_id": file_id,
                "job_id": job_id,
                "config": self.config,
                "created_at": datetime.now().isoformat()
            }
            
            info_file = self.models_dir / f"model_info_{job_id}.json"
            with open(info_file, 'w') as f:
                json.dump(model_info, f, indent=2)
            
            # AdÄ±m 5: EÄŸitimi izle
            model_name = self.step5_monitor_training(manager, job_id)
            
            # Model bilgilerini gÃ¼ncelle
            model_info["fine_tuned_model"] = model_name
            model_info["completed_at"] = datetime.now().isoformat()
            
            with open(info_file, 'w') as f:
                json.dump(model_info, f, indent=2)
            
            # AdÄ±m 6: Modeli test et
            self.step6_test_model(manager, model_name)
            
            print("\n" + "="*60)
            print("ğŸ‰ FINE-TUNING TAMAMLANDI!")
            print("="*60)
            print(f"Model: {model_name}")
            print(f"Bilgi dosyasÄ±: {info_file}")
            
        except Exception as e:
            print(f"\nâŒ Hata: {e}")
            raise


def main():
    parser = argparse.ArgumentParser(description='Fine-tuning eÄŸitim yÃ¶netimi')
    parser.add_argument('--config', type=Path, help='KonfigÃ¼rasyon dosyasÄ±')
    parser.add_argument('--skip-validation', action='store_true', 
                       help='Veri doÄŸrulamayÄ± atla')
    parser.add_argument('--sample', type=int, default=0,
                       help='Ã–rnek veri boyutu (0 = tÃ¼m veri)')
    
    args = parser.parse_args()
    
    # Pipeline oluÅŸtur
    pipeline = TrainingPipeline(args.config)
    
    # Sample size override
    if args.sample > 0:
        pipeline.config['data']['sample_size'] = args.sample
    
    # Pipeline'Ä± Ã§alÄ±ÅŸtÄ±r
    pipeline.run_full_pipeline()


if __name__ == '__main__':
    main() 